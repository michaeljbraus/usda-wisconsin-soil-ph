# dada2.sub

universe = vanilla
log = dada2-$(Cluster).log
error = dada2-$(Cluster).err
# Specifying we need the linux version 7 (for this version of R) and Gluster access
requirements = (OpSys == "LINUX") && (Target.HasGluster == true)

# Notify by email when finished
notification = Complete
notify_user = twhitman@wisc.edu

# Specify your executable (single binary or a script that runs several
#  commands), arguments, and a files for HTCondor to store standard
#  output (or "screen output").
executable = dada2.sh
output = dada2-$(Cluster).out
#
# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to run.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_input_files = dada2.R
# Bringing over the R installation file and the R script we'll run
#
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 16
request_memory = 100GB
request_disk = 10GB
# Updated memory after failed run:
# Memory was only at 30GB (requested 60GB) - will request more cpus and memory to make faster
# Disk took 3-4GB (requested 10GB) - that should be fine

queue

